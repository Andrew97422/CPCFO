{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting parse_hh_data\n",
      "  Downloading parse-hh-data-0.1.14.tar.gz (7.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beautifulsoup4==4.8.2 (from parse_hh_data)\n",
      "  Obtaining dependency information for beautifulsoup4==4.8.2 from https://files.pythonhosted.org/packages/cb/a1/c698cf319e9cfed6b17376281bd0efc6bfc8465698f54170ef60a485ab5d/beautifulsoup4-4.8.2-py3-none-any.whl.metadata\n",
      "  Downloading beautifulsoup4-4.8.2-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting random-user-agent==1.0.1 (from parse_hh_data)\n",
      "  Obtaining dependency information for random-user-agent==1.0.1 from https://files.pythonhosted.org/packages/61/88/8a953b6f08d7cc709695be1a640cdd3a50996636e675381c2b3ec2d7ec44/random_user_agent-1.0.1-py3-none-any.whl.metadata\n",
      "  Downloading random_user_agent-1.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting requests==2.23.0 (from parse_hh_data)\n",
      "  Obtaining dependency information for requests==2.23.0 from https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading requests-2.23.0-py2.py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting tqdm==4.44.1 (from parse_hh_data)\n",
      "  Obtaining dependency information for tqdm==4.44.1 from https://files.pythonhosted.org/packages/1c/1a/cd6ee6b8b06557dcc5590785af2fe90fa10c19c28e567c1e3a299d5081e7/tqdm-4.44.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.44.1-py2.py3-none-any.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3==1.25.8 (from parse_hh_data)\n",
      "  Obtaining dependency information for urllib3==1.25.8 from https://files.pythonhosted.org/packages/e8/74/6e4f91745020f967d09332bb2b8b9b10090957334692eb88ea4afe91b77f/urllib3-1.25.8-py2.py3-none-any.whl.metadata\n",
      "  Downloading urllib3-1.25.8-py2.py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /Users/samedi/Library/Python/3.10/lib/python/site-packages (from beautifulsoup4==4.8.2->parse_hh_data) (2.3.2.post1)\n",
      "Collecting chardet<4,>=3.0.2 (from requests==2.23.0->parse_hh_data)\n",
      "  Obtaining dependency information for chardet<4,>=3.0.2 from https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting idna<3,>=2.5 (from requests==2.23.0->parse_hh_data)\n",
      "  Obtaining dependency information for idna<3,>=2.5 from https://files.pythonhosted.org/packages/a2/38/928ddce2273eaa564f6f50de919327bf3a00f091b5baba8dfa9460f3a8a8/idna-2.10-py2.py3-none-any.whl.metadata\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests==2.23.0->parse_hh_data) (2022.9.24)\n",
      "Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading random_user_agent-1.0.1-py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading requests-2.23.0-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.44.1-py2.py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-1.25.8-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: parse_hh_data\n",
      "  Building wheel for parse_hh_data (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for parse_hh_data: filename=parse_hh_data-0.1.14-py3-none-any.whl size=8438 sha256=00af751ae11603fbb4d81b4aced6efe813f406e8b9f7936cd1cce8935056f6f6\n",
      "  Stored in directory: /Users/samedi/Library/Caches/pip/wheels/c6/a4/ab/f9da281ca144479ecc5e4f85c426d0c59e6d799e50a4835a00\n",
      "Successfully built parse_hh_data\n",
      "Installing collected packages: random-user-agent, chardet, urllib3, tqdm, idna, beautifulsoup4, requests, parse_hh_data\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.12\n",
      "    Uninstalling urllib3-1.26.12:\n",
      "      Successfully uninstalled urllib3-1.26.12\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.11.1\n",
      "    Uninstalling beautifulsoup4-4.11.1:\n",
      "      Successfully uninstalled beautifulsoup4-4.11.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.2\n",
      "    Uninstalling requests-2.28.2:\n",
      "      Successfully uninstalled requests-2.28.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dnnr 0.1.2 requires tqdm<5.0.0,>=4.64.0, but you have tqdm 4.44.1 which is incompatible.\n",
      "lightning 2.1.0 requires tqdm<6.0,>=4.57.0, but you have tqdm 4.44.1 which is incompatible.\n",
      "pytorch-lightning 2.0.3 requires tqdm>=4.57.0, but you have tqdm 4.44.1 which is incompatible.\n",
      "selenium 4.5.0 requires urllib3[socks]~=1.26, but you have urllib3 1.25.8 which is incompatible.\n",
      "sentry-sdk 1.24.0 requires urllib3>=1.26.11; python_version >= \"3.6\", but you have urllib3 1.25.8 which is incompatible.\n",
      "streamlink 5.5.1 requires requests<3.0,>=2.26.0, but you have requests 2.23.0 which is incompatible.\n",
      "streamlink 5.5.1 requires urllib3<3,>=1.26.0, but you have urllib3 1.25.8 which is incompatible.\n",
      "twine 5.0.0 requires urllib3>=1.26.0, but you have urllib3 1.25.8 which is incompatible.\n",
      "ultralytics 8.0.111 requires tqdm>=4.64.0, but you have tqdm 4.44.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed beautifulsoup4-4.8.2 chardet-3.0.4 idna-2.10 parse_hh_data-0.1.14 random-user-agent-1.0.1 requests-2.23.0 tqdm-4.44.1 urllib3-1.25.8\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install parse_hh_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_hh_data import download, parse\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP error occurred: 404 Client Error: Not Found for url: https://api.hh.ru/vacancies/96441501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A second request to the https://api.hh.ru/vacancies/96441501 will be sent in 10 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP error occurred: 404 Client Error: Not Found for url: https://api.hh.ru/vacancies/96486334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A second request to the https://api.hh.ru/vacancies/96486334 will be sent in 10 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP error occurred: 404 Client Error: Not Found for url: https://api.hh.ru/vacancies/96466739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A second request to the https://api.hh.ru/vacancies/96466739 will be sent in 10 seconds\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('/Users/samedi/Documents/Coding/Hakatons/CPCFO/notebooks/train_GB_PodborKursov.xlsx', sheet_name=0, skiprows=3)\n",
    "df = df.dropna(how='all').ffill()\n",
    "# vac_ids = df['Список вакансий'].apply(lambda s: str(s)[22:].split('?')[0]).astype(int).values\n",
    "# vac_ids = vac_ids[vac_ids != '']\n",
    "# vac_ids = vac_ids.astype(int).values\n",
    "\n",
    "names = {}\n",
    "descs = {}\n",
    "skills = {}\n",
    "roles = {}\n",
    "targets = {}\n",
    "for _, row in df.iterrows():\n",
    "    id = str(row[2])[22:].split('?')[0]\n",
    "\n",
    "    try:\n",
    "        v = download.vacancy(id, max_requests_number=1)\n",
    "    except:\n",
    "        continue\n",
    "    names[id] = v['name']\n",
    "    descs[id] = re.sub('<[^<]+>', '', v['description'])\n",
    "    skills[id] = ','.join([i['name'] for i in v['key_skills']])\n",
    "    roles[id] = ','.join([i['name'] for i in v['professional_roles']])\n",
    "    targets[id] = row[0]\n",
    "vacs = pd.DataFrame({'title':names, 'description':descs, 'skills':skills, 'roles':roles, 'target':targets})\n",
    "vacs.to_csv('vacancies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
